---
layout: post
title: "Linux内核数据包处理流程-数据包接收"
description: "Linux内核数据包处理流程-数据包接收"
categories: [kernel,linux]
tags: []
---

该文章以e100为例，简述了数据包接收的流程。

###网卡:


大多数网卡都是一个PCI设备，PCI设备都包含了一个标准的**配置寄存器，寄存器中，包含了PCI设备的厂商ID、设备ID**等等信息，驱动程序使用来描述这些寄存器的标识符

	struct pci_device_id {
	        __u32 vendor, device;                /* Vendor and device ID or PCI_ANY_ID*/
	        __u32 subvendor, subdevice;        /* Subsystem ID's or PCI_ANY_ID */
	        __u32 class, class_mask;        /* (class,subclass,prog-if) triplet */
	        kernel_ulong_t driver_data;        /* Data private to the driver */
	};


在驱动程序中，针对一个设备会定义一个struct pci_device_id 类型的数组，告诉内核支持不同类型的PCI设备的列表，以e100驱动为例：

	#define INTEL_8255X_ETHERNET_DEVICE(device_id, ich) {\
	        PCI_VENDOR_ID_INTEL, device_id, PCI_ANY_ID, PCI_ANY_ID, \
	        PCI_CLASS_NETWORK_ETHERNET << 8, 0xFFFF00, ich }
	        
	static struct pci_device_id e100_id_table[] = {
	        INTEL_8255X_ETHERNET_DEVICE(0x1029, 0),
	        INTEL_8255X_ETHERNET_DEVICE(0x1030, 0),
	        INTEL_8255X_ETHERNET_DEVICE(0x1031, 3),
			……/*略*/
	        { 0, }
	};


在内核中，一个PCI设备，使用struct pci_driver结构来描述，

	struct pci_driver {
	        struct list_head node;
	        char *name;
	        struct module *owner;
	        const struct pci_device_id *id_table;        /* must be non-NULL for probe to be called */
	        int  (*probe)  (struct pci_dev *dev, const struct pci_device_id *id);        /* New device inserted */
	        void (*remove) (struct pci_dev *dev);        /* Device removed (NULL if not a hot-plug capable driver) */
	        int  (*suspend) (struct pci_dev *dev, pm_message_t state);        /* Device suspended */
	        int  (*resume) (struct pci_dev *dev);                        /* Device woken up */
	        int  (*enable_wake) (struct pci_dev *dev, pci_power_t state, int enable);   /* Enable wake event */
	        void (*shutdown) (struct pci_dev *dev);
	
	        struct device_driver        driver;
	        struct pci_dynids dynids;
	};


系统引导的时候，内核发现一个已经检测到的设备同驱动注册的id_table中的信息相匹配时，
它就会触发该驱动的probe函数，以e100为例：

	static struct pci_driver e100_driver = {
		.name =         DRV_NAME,
		.id_table =     e100_id_table,
		.probe =        e100_probe,
		.remove =       e100_remove,
	#ifdef CONFIG_PM
		/* Power Management hooks */
		.suspend =      e100_suspend,
		.resume =       e100_resume,
	#endif
		.shutdown =     e100_shutdown,
		.err_handler = &e100_err_handler,
	};


驱动设备在init函数中，调用pci_module_init函数初始化PCI设备e100_driver:

	static int __init e100_init_module(void)
	{
		if (((1 << debug) - 1) & NETIF_MSG_DRV) {
			pr_info("%s, %s\n", DRV_DESCRIPTION, DRV_VERSION);
			pr_info("%s\n", DRV_COPYRIGHT);
		}
		return pci_register_driver(&e100_driver);
	}

这样，e100_probe将得到调用，改函数主要工作：

1、分配/初始化/注册网络设备；

2、完成PCI设备的I/O区域的分配和映射，以及完成硬件的其它初始化工作；

当probe函数被调用，证明已经发现了我们所支持的网卡，这样，就可以调用register_netdev函数向内核注册网络设备了，注册之前调用alloc_etherdev为以太网分配一个net_device，然后初始化它的重要成员。

**e100_probe:**

	static int __devinit e100_probe(struct pci_dev *pdev,
	        const struct pci_device_id *ent)
	{
	        struct net_device *netdev;
	        struct nic *nic;
	        int err;
	
	        /*分配网络设备*/
	        if(!(netdev = alloc_etherdev(sizeof(struct nic)))) {
	                if(((1 << debug) - 1) & NETIF_MSG_PROBE)
	                        printk(KERN_ERR PFX "Etherdev alloc failed, abort.\n");
	                return -ENOMEM;
	        }
	
	        /*设置各成员指针函数*/
	        netdev->open = e100_open;
	        netdev->stop = e100_close;pci_set_drvdata
	        netdev->hard_start_xmit = e100_xmit_frame;
	        netdev->get_stats = e100_get_stats;
	        netdev->set_multicast_list = e100_set_multicast_list;
	        netdev->set_mac_address = e100_set_mac_address;
	        netdev->change_mtu = e100_change_mtu;
	        netdev->do_ioctl = e100_do_ioctl;
	        SET_ETHTOOL_OPS(netdev, &e100_ethtool_ops);
	        netdev->tx_timeout = e100_tx_timeout;
	        netdev->watchdog_timeo = E100_WATCHDOG_PERIOD;
	        netdev->poll = e100_poll;
	        netdev->weight = E100_NAPI_WEIGHT;
	#ifdef CONFIG_NET_POLL_CONTROLLER
	        netdev->poll_controller = e100_netpoll;
	#endif
	        /*设置网络设备名称*/
	        strcpy(netdev->name, pci_name(pdev));
	
	        /*取得设备私有数据结构*/
	        nic = netdev_priv(netdev);
	        /*网络设备指针，指向自己*/
	        nic->netdev = netdev;
	        /*PCIy设备指针，指向自己*/
	        nic->pdev = pdev;
	        nic->msg_enable = (1 << debug) - 1;
	        
	        /*将PCI设备的私有数据区指向网络设备*/
	        pci_set_drvdata(pdev, netdev);
	
	        /*激活PCI设备*/
	        if((err = pci_enable_device(pdev))) {
	                DPRINTK(PROBE, ERR, "Cannot enable PCI device, aborting.\n");
	                goto err_out_free_dev;
	        }
	
	        /*判断I/O区域是否是I/O内存，如果不是，则报错退出*/
	        if(!(pci_resource_flags(pdev, 0) & IORESOURCE_MEM)) {
	                DPRINTK(PROBE, ERR, "Cannot find proper PCI device "
	                        "base address, aborting.\n");
	                err = -ENODEV;
	                goto err_out_disable_pdev;
	        }
	
	        /*分配I/O内存区域*/
	        if((err = pci_request_regions(pdev, DRV_NAME))) {
	                DPRINTK(PROBE, ERR, "Cannot obtain PCI resources, aborting.\n");
	                goto err_out_disable_pdev;
	        }
	
	        if((err = pci_set_dma_mask(pdev, 0xFFFFFFFFULL))) {
	                DPRINTK(PROBE, ERR, "No usable DMA configuration, aborting.\n");
	                goto err_out_free_res;
	        }
	
	        SET_MODULE_OWNER(netdev);
	        SET_NETDEV_DEV(netdev, &pdev->dev);
	
	        /*分配完成后，映射I/O内存*/
	        nic->csr = ioremap(pci_resource_start(pdev, 0), sizeof(struct csr));
	        if(!nic->csr) {
	                DPRINTK(PROBE, ERR, "Cannot map device registers, aborting.\n");
	                err = -ENOMEM;
	                goto err_out_free_res;
	        }
	
	        if(ent->driver_data)
	                nic->flags |= ich;
	        else
	                nic->flags &= ~ich;
	
	        /*设置设备私有数据结构的大部份默认参数*/
	        e100_get_defaults(nic);
	
	        /* 初始化自旋锁，锅的初始化必须在调用 hw_reset 之前执行*/
	        spin_lock_init(&nic->cb_lock);
	        spin_lock_init(&nic->cmd_lock);
	
	        /* 硬件复位，通过向指定I/O端口设置复位指令实现. */
	        e100_hw_reset(nic);

	        pci_set_master(pdev);
	
	        /*添加两个内核定时器，watchdog和blink_timer*/
	        init_timer(&nic->watchdog);
	        nic->watchdog.function = e100_watchdog;
	        nic->watchdog.data = (unsigned long)nic;
	        init_timer(&nic->blink_timer);
	        nic->blink_timer.function = e100_blink_led;
	        nic->blink_timer.data = (unsigned long)nic;
	
	        INIT_WORK(&nic->tx_timeout_task,
	                (void (*)(void *))e100_tx_timeout_task, netdev);
	
	        if((err = e100_alloc(nic))) {
	                DPRINTK(PROBE, ERR, "Cannot alloc driver memory, aborting.\n");
	                goto err_out_iounmap;
	        }
	
	        
	        e100_phy_init(nic);
	
	        if((err = e100_eeprom_load(nic)))
	                goto err_out_free;
	
	        memcpy(netdev->dev_addr, nic->eeprom, ETH_ALEN);
	        if(!is_valid_ether_addr(netdev->dev_addr)) {
	                DPRINTK(PROBE, ERR, "Invalid MAC address from "
	                        "EEPROM, aborting.\n");
	                err = -EAGAIN;
	                goto err_out_free;
	        }
	
	        /* Wol magic packet can be enabled from eeprom */
	        if((nic->mac >= mac_82558_D101_A4) &&
	           (nic->eeprom[eeprom_id] & eeprom_id_wol))
	                nic->flags |= wol_magic;
	
	        /* ack any pending wake events, disable PME */
	        pci_enable_wake(pdev, 0, 0);
	
	        /*注册网络设备*/
	        strcpy(netdev->name, "eth%d");
	        if((err = register_netdev(netdev))) {
	                DPRINTK(PROBE, ERR, "Cannot register net device, aborting.\n");
	                goto err_out_free;
	        }
	
	        return 0;
	
			....//略
	}


etdev\-\>open = e100_open;

指定了设备的open函数为e100_open，这样，当第一次使用设备，比如使用ifconfig工具的时候，open函数将被调用


注：
3.1内核的代码直接**netdev\->netdev\_ops = &e100\_netdev\_ops**，而且添加了**napi技术**(该技术会提高网络处理效率，核心在于不采用中断方式读取数据，采用中断唤醒数据接收的服务程序，由该程序轮询处理数据)支持

	netif_napi_add(netdev, &nic->napi, e100_poll, E100_NAPI_WEIGHT);
	软中断处理函数net_rx_action 将调用e100_poll


###打开设备:

**e100_open** 接口会调用e100\_up
	
	static int e100_open(struct net_device *netdev)
	{
		struct nic *nic = netdev_priv(netdev);
		int err = 0;
	
		netif_carrier_off(netdev);
		if ((err = e100_up(nic)))
			netif_err(nic, ifup, nic->netdev, "Cannot open interface, aborting\n");
		return err;
	}

大多数涉及物理设备可以感知信号载波（carrier）的存在，载波的存在意味着设备可以工作
据个例子来讲：当一个用户拔掉了网线，也就意味着信号载波的消失。
netif_carrier_off：关闭载波信号；

**e100_up:**

	static int e100_up(struct nic *nic)
	{
		int err;
	
		....//略
		e100_set_multicast_list(nic->netdev);
		e100_start_receiver(nic, NULL);
		mod_timer(&nic->watchdog, jiffies);
		if ((err = request_irq(nic->pdev->irq, e100_intr, IRQF_SHARED,
			nic->netdev->name, nic->netdev)))
			goto err_no_irq;
		netif_wake_queue(nic->netdev);
		napi_enable(&nic->napi);
		/* enable ints _after_ enabling poll, preventing a race between
		 * disable ints+schedule */
		e100_enable_irq(nic);
		return 0;

		....//略
		
	}

主要调用request\_irq注册中断，当有数据来时，中断接口e100\_intr将会调用
检测中断合法性等问题后会调用\__napi\_schedule NAPI的调度函数。

把设备的napi\_struct实例添加到当前CPU的softnet\_data的poll\_list中，以便于接下来进行轮询。然后设置NET\_RX\_SOFTIRQ标志位来触发软中断。

	static inline void ____napi_schedule(struct softnet_data *sd,
					     struct napi_struct *napi)
	{
		list_add_tail(&napi->poll_list, &sd->poll_list);
		__raise_softirq_irqoff(NET_RX_SOFTIRQ);
	}

软中断(NET\_RX\_SOFTIRQ)的处理函数net\_rx\_action()主要做了：

遍历sd\->poll\_list，对于每个处于轮询状态的设备，调用它的**poll()**函数来处理数据包。
如果设备NAPI被禁止了，则把设备从sd\->poll\_list上删除，否则把设备移动到sd\->poll\_list的队尾。
每次软中断最多允许处理netdev\_budget(300)个数据包，最长运行时间为2jiffies(2ms)。
每个设备一次最多允许处理weight\_p(64)个数据包(非NAPI)。
如果在这次软中断中没处理玩，则再次设置**NET\_RX\_SOFTIRQ**标志触发软中断。


e100_poll:**该接口的调用是有dev.c软中断触发的net_rx_action**调用的：

	static int e100_poll(struct napi_struct *napi, int budget)
	{
		struct nic *nic = container_of(napi, struct nic, napi);
		unsigned int work_done = 0;
		/*进行数据包的接收和传输*/  
		e100_rx_clean(nic, &work_done, budget);
		e100_tx_clean(nic);
	
		/* If budget not fully consumed, exit the polling mode */
		if (work_done < budget) {
			napi_complete(napi);
			e100_enable_irq(nic);
		}
	
		return work_done;
	}

在 e100_rx_clean函数中会遍历环形缓冲区，接收数据
	
	e100_rx_clean-> e100_rx_indicate -> netif_receive_skb

e100_rx_indicate 函数中会设置skb，
netif_receive_skb这个函数是L2和L3的接口函数，就这样push到了上层


###队列层
以上就是上半部，现在讨论软中断与下半部（为了减少中断处理的工作量，比如，一般中断处理时，需要屏蔽其它中断，如果中断处理时间过长，那么其它中断有可能得不到及时处理，也以，有一种机制，就是把“不必马上处理”的工作，推迟一点，让它在中断处理后的某一个时刻得到处理。这就是下半部）

	open_softirq(NET_RX_SOFTIRQ, net_rx_action, NULL);

向内核注册一个名为NET_RX_SOFTIR的软中断，net_rx_action是软中断的处理函数。


然后，在驱动中断处理完后的某一个时刻，调用

	raise_softirq_irqoff(NET_RX_SOFTIRQ)；

触发它，这样net\_rx\_action将得到执行。

队列层中，包含了一个叫做struct softnet\_data：


	CODE:
	struct softnet_data
	{
	        /*throttle 用于拥塞控制，当拥塞发生时，throttle将被设置，后续进入的数据包将被丢弃*/
	        int                        throttle;
	        /*netif_rx函数返回的拥塞级别*/
	        int                        cng_level;
	        int                        avg_blog;
	        /*softnet_data 结构包含一个指向接收和传输队列的指针，input_pkt_queue成员指向准备传送
	        给网络层的sk_buffs包链表的首部的指针，这个队列中的包是由netif_rx函数递交的*/
	        struct sk_buff_head        input_pkt_queue;
	        
	        struct list_head        poll_list;
	        struct net_device        *output_queue;
	        struct sk_buff                *completion_queue;
	
	        struct net_device        backlog_dev;        /* Sorry. 8) */
	};

内核使用了一个同名的变量softnet\_data，它是一个Per-CPU变量，每个CPU都有一个。

	net/core/dev.c

	CODE:
	DECLARE_PER_CPU(struct softnet_data,softnet_data);
	CODE:
	/*
	*       网络模块的核心处理模块.
	*/
	static int __init net_dev_init(void)
	{
	        int i, rc = -ENOMEM;
	
	        BUG_ON(!dev_boot_phase);
	
	        net_random_init();
	
	        if (dev_proc_init())                /*初始化proc文件系统*/
	                goto out;
	
	        if (netdev_sysfs_init())        /*初始化sysfs文件系统*/
	                goto out;
	
	        /*ptype_all和ptype_base是重点，后面会详细分析，它们都是
	        struct list_head类型变量，这里初始化链表成员*/
	        INIT_LIST_HEAD(&ptype_all);
	        for (i = 0; i < 16; i++) 
	                INIT_LIST_HEAD(&ptype_base[i]);
	
	        for (i = 0; i < ARRAY_SIZE(dev_name_head); i++)
	                INIT_HLIST_HEAD(&dev_name_head[i]);
	
	        for (i = 0; i < ARRAY_SIZE(dev_index_head); i++)
	                INIT_HLIST_HEAD(&dev_index_head[i]);
	
	        /*
	         *        初始化包接收队列，这里我们的重点了.
	         */
	
	        /*遍历每一个CPU，取得它的softnet_data，我们说过，它是一个struct softnet_data的Per-CPU变量*/
	        for (i = 0; i < NR_CPUS; i++) {
	                struct softnet_data *queue;
	                
	                /*取得第i个CPU的softnet_data，因为队列是包含在它里边的，所以，我会直接说，“取得队列”*/
	                queue = &per_cpu(softnet_data, i);
	                /*初始化队列头*/
	                skb_queue_head_init(&queue->input_pkt_queue);
	                queue->throttle = 0;
	                queue->cng_level = 0;
	                queue->avg_blog = 10; /* arbitrary non-zero */
	                queue->completion_queue = NULL;
	                INIT_LIST_HEAD(&queue->poll_list);
	                set_bit(__LINK_STATE_START, &queue->backlog_dev.state);
	                queue->backlog_dev.weight = weight_p;
	                /*这里，队列中backlog_dev设备，它是一个伪网络设备，不对应任何物理设备，它的poll函数，指向了
	                process_backlog，后面我们会详细分析*/
	                queue->backlog_dev.poll = process_backlog;
	                atomic_set(&queue->backlog_dev.refcnt, 1);
	        }
	
	#ifdef OFFLINE_SAMPLE
	        samp_timer.expires = jiffies + (10 * HZ);
	        add_timer(&samp_timer);
	#endif
	
	        dev_boot_phase = 0;
	        
	        /*注册收/发软中断*/
	        open_softirq(NET_TX_SOFTIRQ, net_tx_action, NULL);
	        open_softirq(NET_RX_SOFTIRQ, net_rx_action, NULL);
	
	        hotcpu_notifier(dev_cpu_callback, 0);
	        dst_init();
	        dev_mcast_init();
	        rc = 0;
	out:
	        return rc;
	}


net\_rx\_action ，会调用e100 注册的e100_poll，最终调用netif_receive_skb push skb到上层,轮询接收数据，提高网络效率，也是在这里发生的。

	
	static void net_rx_action(struct softirq_action *h)
	{
	    struct softnet_data *sd = &__get_cpu_var(softnet_data); /* 当前CPU的softnet_data实例 */
	    unsigned long time_limit = jiffies + 2; /* 一次软中断的最长处理时间(2ms) */
	    int budget = netdev_budget; /* 一次软中断最多能够处理的skb个数(300) */
	    void *have;
	
	    local_irq_disable(); /* 禁止本地中断 */
	
	    /* 如果有处于轮询状态的设备 */
	    while(! list_empty(&sd->poll_list)) {
	
	        struct napi_struct *n;
	        int work, weight;
	      
	        /* If softirq window is exhuasted then punt.
	         * Allow this to run for 2 jiffies since which will allow an average
	         * latency of 1.5/HZ.
	         * 如果处理的数据包过多了，或者处理的时间过长了，则退出。
	         */
	        if (unlikely(budget <= 0 || time_after(jiffies, time_limit)))
	            goto softnet_break;
	
	        local_irq_enable(); /* 开启本地中断 */
	
	        /* Even though interrupts have been re-enabled, this access is safe because
	         * interrupts can only add new entries to the tail of this list, and only ->poll()
	         * calls can remove this head entry from the list.
	         */
	
	        /* 获取链表上的第一个napi_struct实例 */
	        n = list_first_entry(&sd->poll_list, struct napi_struct, poll_list);
	
	        have = netpoll_poll_lock(n);
	        weight = n->weight; /* 这个设备每次能poll的数据包上限 */
	
	        /* This NAPI_STATE_SCHED test is for avoiding a race with netpoll's
	         * poll_napi(). Only the entity which obtains the lock and sees NAPI_STATE_SCHED
	         * set will actually make the ->poll() call. Therefore we avoid accidently calling ->poll()
	         * when NAPI is not scheduled.
	         */
	        work = 0;
	
	        if (test_bit(NAPI_STATE_SCHED, &n->state)) {
	            /* 调用napi_struct的poll方法，返回处理的数据包个数 */
	            work = n->poll(n, weight); /* 默认为process_backlog()  ,这里为注册的 e100_poll*/
	
	            trace_napi_poll(n);
	        }
	        WARN_ON_ONCE(work > weight);
	
	        budget -= work; /* 总预算减去本次处理的数据包数 */
	
	        local_irq_disable(); /* 禁止本地中断 */
	
	        if (unlikely(work == weight)) {
	            /* 如果NAPI被禁止了，则把当前napi_struct从poll_list中删除 */
	            if (unlikely(napi_disable_pending(n))) {
	                local_irq_enable();
	                napi_complete(n);
	                local_irq_disable();
	
	            } else
	                /* 把当前napi_struct移动到poll_list的队尾 */
	                list_move_tail(&n->poll_list, &sd->poll_list);
	        }
	        netpoll_poll_unlock(have);
	    }
	
	out:
	    net_rps_action_and_irq_enable(sd); /* 开启本地中断 */
	
	#ifdef CONFIG_NET_DMA
	    ...
	#endif
	
	    return;
	
	softnet_break:
	    sd->time_squeeze++; /* 跑满2ms，或处理了300个包 */
	    __raise_softirq_irqoff(NET_RX_SOFTIRQ); /* 因为没处理完，再次触发软中断 */
	    goto out;
	}





**注：NAPI和非API 处理差异:**

![usbnet](/images/usbnet.png)

